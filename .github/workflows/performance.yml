# This is a workflow triggered by PR or triggered manually
# Runs quick performance tests and reports the comparison against HEAD
# Test should take less than 10 minutes to run on current self-hosted devices
name: "Performance Testing"

# Controls when the action will run. 
# Workflow runs when manually triggered using the UI or API.
on:
  push:
   # branches: [ main ]
  pull_request:
    branches: [ main ]
    
# Env variables
env: 
  SG_COMMIT: 649509c
  
jobs:
  Performance_x86-64:
    name: Performance x86-64
    runs-on: [self-hosted, linux, x86-64]
    # Inputs the workflow accepts.
    steps:
      - run: echo "This job is now running on a ${{ runner.os }} self-hosted server!"
      - name: Setup Rust Toolchain
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - name: Build sightglass commit ${{env.SG_COMMIT}}"
        run: |
          cd ../ && ls -l && rm -rf ./sightglass
          git clone https://github.com/bytecodealliance/sightglass.git && cd ./sightglass
          git checkout 649509c
          cargo build --release
      - uses: actions/checkout@v2
        with: 
          submodules: true
          path: wasmtime_commit
      - run: echo "The name of your commit branch is ${{ github.ref }} and your commit repository is ${{ github.repository }}."
      - name: Build ${{ github.ref }}
        working-directory: ./wasmtime_commit
        run: |
          cargo build --release -p wasmtime-bench-api
          cp target/release/libwasmtime_bench_api.so /tmp/wasmtime_commit.so
      - uses: actions/checkout@v2
        with:
          ref: 'main'
          submodules: true
          path: wasmtime_main
      - name: Build Main
        working-directory: ./wasmtime_main
        run: |
          cargo build --release -p wasmtime-bench-api
          cp target/release/libwasmtime_bench_api.so /tmp/wasmtime_main.so
      - name: Run performance tests
        working-directory: ../sightglass
        run: |
          cargo run -- \
          benchmark \
          --processes 1 \
          --iterations-per-process 1 \
          --engine /tmp/wasmtime_main.so \
          --engine /tmp/wasmtime_commit.so \
          --output-format json \
          --output-file results.json
          -- benchmarks-next/blake3-scalar/benchmark.wasm
      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action/composite@v1
        if: always()
        with:
          name: Perf Comparison
          files: ./results.json

 # Performance_Aarch64:
 #   name: Performance Aarch64
 #   runs-on: [self-hosted, linux, x86-64]       
        

